# -*- coding: utf-8 -*-
"""TBIR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_zu50fSQKjDzEwMCO6IDEHK6I3gEA12d
"""

!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
!pip install ftfy regex tqdm
!pip install git+https://github.com/openai/CLIP.git
!mkdir -p ~/.kaggle
!kaggle datasets download -d adityajn105/flickr8k
!pip install kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json


!kaggle datasets download -d adityajn105/flickr8k
!unzip flickr8k.zip -d /content/flickr8k
captions_file = "/content/flickr8k/captions.txt"
image_dir = "/content/flickr8k/Images"

import clip
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

checkpoint_path = "/content/fine_tuned_clip_final.pth"
model.load_state_dict(torch.load(checkpoint_path, map_location=device))
model.eval()

print("Model loaded successfully and ready")

import matplotlib.pyplot as plt
from PIL import Image


def test_caption(model, image_features_dict, caption, device, top_k=10):
    model.eval()
    with torch.no_grad():

        text_features = model.encode_text(clip.tokenize([caption]).to(device))
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)


        similarities = {
            path: torch.nn.functional.cosine_similarity(text_features, feat).item()
            for path, feat in image_features_dict.items()
        }


        top_k_paths = sorted(similarities, key=similarities.get, reverse=True)[:top_k]
        return top_k_paths

def visualize_retrieved_images(caption, top_images, top_k=10):

    plt.figure(figsize=(15, 8))


    plt.suptitle("Proposed model "f"Caption: {caption}", fontsize=16, y=0.95)


    for i, image_path in enumerate(top_images[:top_k]):
        plt.subplot(1, top_k, i + 1)
        retrieved_image = Image.open(image_path)
        plt.imshow(retrieved_image)
        plt.axis("off")
        plt.title(f"Retrieved {i + 1}", fontsize=10)


    plt.tight_layout()
    plt.show()


example_caption = "Man working on computer"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


top_images = test_caption(model, image_features_dict, example_caption, device, top_k=10)


print("Top matching images for the caption:")
for i, image_path in enumerate(top_images):
    print(f"Rank {i + 1}: {image_path}")


visualize_retrieved_images(example_caption, top_images, top_k=10)